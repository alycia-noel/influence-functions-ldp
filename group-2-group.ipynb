{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f320e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import fairlearn.datasets\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import grad\n",
    "from torch.autograd.functional import vhp\n",
    "from get_datasets import get_diabetes, get_adult, get_law\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "E = math.e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88723b",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd5b9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(e_k_actual, e_k_estimated, ep, k_):\n",
    "\n",
    "    #e_k_estimated = [-1*ek for ek in e_k_estimated]\n",
    "    fig, ax = plt.subplots()\n",
    "    palette = sns.color_palette(\"cool\", len(e_k_actual))\n",
    "    sns.set(font_scale=1.15)\n",
    "    sns.set_style(style='white')\n",
    "    min_x = np.min(e_k_actual)\n",
    "    max_x = np.max(e_k_actual)\n",
    "    min_y = np.min(e_k_estimated)\n",
    "    max_y = np.max(e_k_estimated)\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = 6, 5\n",
    "    z = np.polyfit(e_k_actual,  e_k_estimated, 1)\n",
    "    p = np.poly1d(z)\n",
    "    xx = np.linspace(-p(2)/p(1), max(e_k_actual)+.0001)\n",
    "    yy = np.polyval(p, xx)\n",
    "    #add trendline to plot\n",
    "    ax.plot(xx, yy, ls=\"-\", color='k')\n",
    "    for k in range(len(e_k_actual)):\n",
    "        ax.scatter(e_k_actual[k], e_k_estimated[k], zorder=2, s=45, color = palette[k], label=ep[k])\n",
    "\n",
    "    ax.set_title(f'Actual vs. Estimated loss for k={k_:.2f}%')\n",
    "    ax.set_xlabel('Actual loss difference')\n",
    "    ax.set_ylabel('Estimated loss difference')\n",
    "   \n",
    "    ax.set_xlim(min_x-.0001, max_x+.0001)\n",
    "    ax.set_ylim(min_y-.0001, max_y+.0001)\n",
    "    \n",
    "   \n",
    "    text = 'MAE = {:.03}\\nP = {:.03}'.format(mean_absolute_error(e_k_actual, e_k_estimated), spearmanr(e_k_actual, e_k_estimated).correlation)\n",
    "    ax.text(max_x+.00009,min_y-.00008, text, verticalalignment='bottom', horizontalalignment='right')\n",
    "#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.tight_layout()\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.show()\n",
    "    # cooler color = smaller epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741afa72",
   "metadata": {},
   "outputs": [],
   "source": [
    " class CreateData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        out_label = self.targets[idx]\n",
    "\n",
    "        return out_data, out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d3bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(new_train_df, feature_set, label, k):    \n",
    "\n",
    "    selected_group = new_train_df.loc[new_train_df['gender'] == 0]\n",
    "\n",
    "    num_to_sample = round((k / 100)*len(selected_group))\n",
    "\n",
    "    sampled_group = selected_group.sample(n=num_to_sample)\n",
    "    not_selected = new_train_df.drop(sampled_group.index)\n",
    "\n",
    "    selected_group_X = sampled_group[feature_set]\n",
    "    selected_group_y = sampled_group[label]\n",
    "\n",
    "    not_selected_group_X = not_selected[feature_set]\n",
    "    not_selected_group_y = not_selected[label]   \n",
    "    \n",
    "    return selected_group_X, selected_group_y, not_selected_group_X, not_selected_group_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e210d31",
   "metadata": {},
   "source": [
    "### Randomized Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20c9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p(epsilon):\n",
    "    probability = float(E ** epsilon) / float(1 + (E ** epsilon))\n",
    "    p = torch.FloatTensor([[probability, 1-probability], [1-probability, probability]])\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07756821",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9daf5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(num_features, 1, bias=False)\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.fc1(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def loss(self, logits, y):\n",
    "        loss = self.criterion(logits.ravel(), y)\n",
    "        \n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        thresh_results = []\n",
    "        \n",
    "        for p in probabilities:\n",
    "            if p>.5:\n",
    "                thresh_results.append(1)\n",
    "            else:\n",
    "                thresh_results.append(0)\n",
    "                \n",
    "        num_correct = 0\n",
    "        for r,y_ in zip(thresh_results, y):\n",
    "            if r == y_:\n",
    "                num_correct += 1\n",
    "                \n",
    "        acc = num_correct / len(y)\n",
    "#         print(\"Accuracy is {0:.3f}\".format(acc*100))\n",
    "#         print(\"Precision is {0:.3f}\".format(precision_score(y.detach().cpu().numpy(), thresh_results, zero_division=0)))\n",
    "#         print(\"Recall is {0:.3f}\".format(recall_score(y.detach().cpu().numpy(), thresh_results)))\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c1a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset):\n",
    "    model.train()\n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), lr=.05, weight_decay=0)\n",
    "    # adult: lr = .001, bs = 32\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "            \n",
    "    train_data = CreateData(dataset[0], dataset[1])\n",
    "    train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    for itr in range(0, 20):\n",
    "        itr_loss = 0\n",
    "        for i, [x,y] in enumerate(train_dataloader):\n",
    "            opt.zero_grad()\n",
    "            oupt = model(x)\n",
    "            \n",
    "            try:\n",
    "                loss_val = criterion(oupt.ravel(), y)\n",
    "            except ValueError:\n",
    "                loss_val = criterion(oupt, y)\n",
    "            itr_loss += loss_val\n",
    "            loss_val.backward()\n",
    "            opt.step() \n",
    "       \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c7499",
   "metadata": {},
   "source": [
    "### Influence Calculation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc60cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_influence_single(model, epsilon, train_data, test_data, group_data, device, num_features, criterion):\n",
    "    start = time.time()\n",
    "    est_hess = explicit_hess(model, train_data, device, criterion)\n",
    "\n",
    "    grad_test = grad_z([test_data[0], test_data[1]], model, device, criterion)\n",
    "    s_test_vec = torch.mm(grad_test[0], est_hess.to(device))\n",
    "\n",
    "    P = get_p(epsilon)\n",
    "    \n",
    "    p_01, p_10 = P[0][1].item(), P[1][0].item()\n",
    "    \n",
    "    pi_1 = sum(list(group_data[1]))\n",
    "    pi_0 = len(group_data[1]) - pi_1\n",
    "    \n",
    "    lam_0 = round(p_01 * pi_1)\n",
    "    lam_1 = round(p_10 * pi_0)\n",
    "\n",
    "    S_pert = 1 - group_data[1]\n",
    "    \n",
    "    y_w_group_pert = pd.concat([group_data[3], S_pert], axis = 0, ignore_index=True)\n",
    "    y_wo_pert = pd.concat([group_data[3], group_data[1]], axis = 0, ignore_index=True)\n",
    "    reconstructed_x = pd.concat([group_data[2], group_data[0]], axis = 0, ignore_index=True)\n",
    "  \n",
    "    assert len(S_pert) == len(group_data[1])\n",
    "    grad_z_vec = grad_training([group_data[0],group_data[1]], S_pert, [model], device, [lam_0, lam_1, epsilon], criterion)\n",
    "    \n",
    "    influence = torch.dot(s_test_vec.flatten(), grad_z_vec[0].flatten()) * (1/len(train_data[0]))\n",
    "    end = time.time() - start\n",
    "\n",
    "    return influence.cpu(), end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b0ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explicit_hess(model, train_data, device, criterion):\n",
    " \n",
    "    logits = model(train_data[0])\n",
    "    loss = criterion(logits.ravel(), train_data[1]) #reduction mean\n",
    "    \n",
    "    grads = grad(loss, model.parameters(), retain_graph=True, create_graph=True)\n",
    "\n",
    "    hess_params = torch.zeros(len(model.fc1.weight[0]), len(model.fc1.weight[0]))\n",
    "    \n",
    "    for i in range(len(model.fc1.weight[0])):\n",
    "        hess_params_ = grad(grads[0][0][i], model.parameters(), retain_graph=True)[0][0]\n",
    "        for j, hp in enumerate(hess_params_):\n",
    "#             if i == j: \n",
    "#                 if hp == 0:\n",
    "#                     hess_params[i,j] = 1e-30\n",
    "#             else:\n",
    "            hess_params[i,j] = hp\n",
    "\n",
    "            \n",
    "    inv_hess = torch.linalg.inv(hess_params)\n",
    "    return inv_hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1656b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_z(test_data, model, device, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_data_features = test_data[0]\n",
    "    test_data_labels = test_data[1]\n",
    "\n",
    "    logits = model(test_data_features)\n",
    "    loss = criterion(logits, torch.atleast_2d(test_data_labels).T) # reduction mean\n",
    "    \n",
    "    return grad(loss, model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ac6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_training(train_data, y_perts, parameters, device, epsilon, criterion):\n",
    "    \n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    \n",
    "    lam_0, lam_1, ep = epsilon\n",
    "    lam = lam_0 + lam_1\n",
    "    len_s = len(y_perts)\n",
    "    \n",
    "    train_data_features = torch.FloatTensor(train_data[0].values).to(device)\n",
    "    train_data_labels = torch.FloatTensor(train_data[1].values).to(device)\n",
    "    train_pert_data_labels = torch.FloatTensor(y_perts.values).to(device)\n",
    "    \n",
    "    model = parameters[0]\n",
    "    model.eval()\n",
    "\n",
    "    logits = model(train_data_features)\n",
    "\n",
    "    orig_loss = criterion(logits, torch.atleast_2d(train_data_labels).T)\n",
    "    pert_loss = criterion(logits, torch.atleast_2d(train_pert_data_labels).T)\n",
    "    loss = float(1/(1 + (E ** ep)))*(pert_loss - orig_loss)\n",
    "    \n",
    "    to_return = grad(loss, model.parameters())\n",
    "    \n",
    "        \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f72f48",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe081fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main(dataset, epsilons, ks, num_rounds):\n",
    "\n",
    "    device = 'cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    \n",
    "    all_orig_loss_e_k = []\n",
    "    all_est_loss_e_k = []\n",
    "    all_time = []\n",
    "    \n",
    "    for nr in range(num_rounds):\n",
    "        print(f'\\nRound {nr+1}')\n",
    "        ############\n",
    "        # Get data #\n",
    "        ############\n",
    "        print('\\nGetting Data...')\n",
    "        if dataset == 'adult':\n",
    "            data = get_adult()\n",
    "            label = 'income_class'\n",
    "        elif dataset == 'diabetes':\n",
    "            data = get_diabetes()\n",
    "            label = 'readmit_binary'\n",
    "        else:\n",
    "            data = get_law()\n",
    "            label = 'admit'\n",
    "\n",
    "        feature_set = set(data.columns) - {label}\n",
    "        num_features = len(feature_set)\n",
    "            \n",
    "        X = data[feature_set]\n",
    "        y = data[label]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "       \n",
    "        new_train_df = pd.concat([X_train, y_train], axis=1)\n",
    "  \n",
    "        train_sample_num = len(X_train)\n",
    "    \n",
    "        x_test_input = torch.FloatTensor(X_test.values).to(device)\n",
    "        y_test_input = torch.FloatTensor(y_test.values).to(device)\n",
    "\n",
    "        x_train_input = torch.FloatTensor(X_train.values).to(device)\n",
    "        y_train_input = torch.FloatTensor(y_train.values).to(device)\n",
    "   \n",
    "        ##############################################\n",
    "        # Train original model and get original loss #\n",
    "        ##############################################\n",
    "        print('Training original model...')\n",
    "        torch_model = LogisticRegression(num_features)\n",
    "        torch.save(torch_model.state_dict(), 'models/initial_config_dia.pth')\n",
    "        torch_model.to(device)\n",
    "        torch_model = train(torch_model, [x_train_input, y_train_input])\n",
    "        test_loss_ori, acc_ori = torch_model.loss(torch_model(x_test_input), y_test_input)\n",
    "\n",
    "        e_k_act_losses = []\n",
    "        e_k_est_losses = []\n",
    "        influence_time = []\n",
    "        \n",
    "        ################################################################\n",
    "        # Perform influence and retraining for all epsilons a k values #\n",
    "        ################################################################\n",
    "        print('\\nBegining epsilon and k rounds')\n",
    "        print('-----------------------------')\n",
    "        for ep in epsilons:\n",
    "            print(f'\\nEpsilon: {ep}')\n",
    "            \n",
    "            k_act_losses = []\n",
    "            k_est_losses = []\n",
    "            inf_time = []\n",
    "            \n",
    "            for k in ks:\n",
    "                # Influence\n",
    "                print(f'k: {k:.2f}')\n",
    "                selected_group_X, selected_group_y, not_selected_group_X, not_selected_group_y = get_data(new_train_df, feature_set, label, k)\n",
    "                print(len(selected_group_X), len(not_selected_group_X), len(selected_group_X)/len(not_selected_group_X))\n",
    "                loss_diff_approx, tot_time = calc_influence_single(torch_model, ep, [x_train_input, y_train_input], [x_test_input, y_test_input], [selected_group_X, selected_group_y, not_selected_group_X, not_selected_group_y], device, num_features, criterion)\n",
    "                loss_diff_approx = -torch.FloatTensor(loss_diff_approx).cpu().numpy()\n",
    "                print(f'Approx difference: {loss_diff_approx:.5f}')\n",
    "                # Retrain\n",
    "                P = get_p(ep)\n",
    "\n",
    "                p_01, p_10 = P[0][1].item(), P[1][0].item()\n",
    "\n",
    "                pi_1 = sum(list(selected_group_y))\n",
    "                pi_0 = len(selected_group_y) - pi_1\n",
    "\n",
    "                lam_0 = round(p_01 * pi_1)\n",
    "                lam_1 = round(p_10 * pi_0)\n",
    "\n",
    "                S = pd.concat([selected_group_X, selected_group_y], axis=1, ignore_index=False)\n",
    "\n",
    "                G0 = S[label][S[label].eq(1)].sample(lam_0).index\n",
    "                G1 = S[label][S[label].eq(0)].sample(lam_1).index\n",
    "\n",
    "                G = S.loc[G0.union(G1)]\n",
    "                not_g = S.drop(G0.union(G1))\n",
    "\n",
    "                G_pert = 1 - G[label]\n",
    "\n",
    "                y_w_group_pert = pd.concat([not_selected_group_y, not_g[label], G_pert], axis = 0, ignore_index=True)\n",
    "                y_wo_pert = pd.concat([not_selected_group_y, not_g[label], G[label]], axis = 0, ignore_index=True)\n",
    "                reconstructed_x = pd.concat([not_selected_group_X, not_g[feature_set], G[feature_set]], axis = 0, ignore_index=True)\n",
    "\n",
    "                model_pert = LogisticRegression(num_features)\n",
    "                model_pert.load_state_dict(torch.load('models/initial_config_dia.pth'))\n",
    "                model_pert.to(device)\n",
    "                model_pert = train(model_pert, [torch.FloatTensor(reconstructed_x.values).to(device), torch.FloatTensor(y_w_group_pert.values).to(device)])\n",
    "                test_loss_retrain, acc_retrain = model_pert.loss(model_pert(x_test_input), y_test_input)\n",
    "\n",
    "                 # get true loss diff\n",
    "                loss_diff_true = (test_loss_retrain - test_loss_ori).detach().cpu().item()\n",
    "                print(f'True difference: {loss_diff_true:.5f}')\n",
    "                k_act_losses.append(loss_diff_true)\n",
    "                k_est_losses.append(loss_diff_approx)\n",
    "                inf_time.append(tot_time)\n",
    "            \n",
    "            e_k_act_losses.append(k_act_losses)\n",
    "            e_k_est_losses.append(k_est_losses)\n",
    "            influence_time.append(inf_time)\n",
    "            \n",
    "        all_orig_loss_e_k.append(e_k_act_losses)\n",
    "        all_est_loss_e_k.append(e_k_est_losses) \n",
    "        all_time.append(influence_time)\n",
    "    \n",
    "    return all_orig_loss_e_k, all_est_loss_e_k, all_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfc9de",
   "metadata": {},
   "source": [
    "### Perform Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2747a8a8",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e3ef67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilons = [.01, .02, .03, .04, .05, .06, .07, .08, .09, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "k = np.linspace(1, 25, 10) # 25 - adult, 30 - diabetes\n",
    "rounds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d8f406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          3.66666667  6.33333333  9.         11.66666667 14.33333333\n",
      " 17.         19.66666667 22.33333333 25.        ]\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d7588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 1\n",
      "\n",
      "Getting Data...\n",
      "Training original model...\n",
      "\n",
      "Begining epsilon and k rounds\n",
      "-----------------------------\n",
      "\n",
      "Epsilon: 0.01\n",
      "k: 1.00\n",
      "428 79165 0.005406429609044401\n",
      "Approx difference: -0.00005\n",
      "True difference: 0.00057\n",
      "k: 3.67\n",
      "1569 78024 0.020109197170101508\n",
      "Approx difference: -0.00006\n",
      "True difference: 0.00073\n",
      "k: 6.33\n",
      "2711 76882 0.035261829817122343\n",
      "Approx difference: -0.00012\n",
      "True difference: 0.00034\n",
      "k: 9.00\n",
      "3852 75741 0.0508575276270448\n",
      "Approx difference: -0.00021\n",
      "True difference: 0.00369\n",
      "k: 11.67\n",
      "4994 74599 0.06694459711256183\n",
      "Approx difference: 0.00022\n",
      "True difference: 0.00112\n",
      "k: 14.33\n",
      "6135 73458 0.08351711181899861\n",
      "Approx difference: -0.00021\n",
      "True difference: 0.00133\n",
      "k: 17.00\n",
      "7277 72316 0.10062780021018862\n",
      "Approx difference: -0.00036\n",
      "True difference: 0.00095\n",
      "k: 19.67\n",
      "8418 71175 0.1182718651211802\n",
      "Approx difference: -0.00024\n",
      "True difference: 0.00553\n",
      "k: 22.33\n",
      "9560 70033 0.1365070752359602\n",
      "Approx difference: -0.00048\n",
      "True difference: 0.00127\n",
      "k: 25.00\n",
      "10701 68892 0.15533008186727051\n",
      "Approx difference: 0.00007\n",
      "True difference: 0.00170\n",
      "\n",
      "Epsilon: 0.02\n",
      "k: 1.00\n",
      "428 79165 0.005406429609044401\n",
      "Approx difference: 0.00001\n",
      "True difference: 0.00281\n",
      "k: 3.67\n",
      "1569 78024 0.020109197170101508\n",
      "Approx difference: -0.00015\n",
      "True difference: 0.00038\n",
      "k: 6.33\n",
      "2711 76882 0.035261829817122343\n",
      "Approx difference: -0.00003\n",
      "True difference: 0.00093\n",
      "k: 9.00\n",
      "3852 75741 0.0508575276270448\n",
      "Approx difference: -0.00022\n",
      "True difference: 0.00073\n",
      "k: 11.67\n",
      "4994 74599 0.06694459711256183\n",
      "Approx difference: -0.00027\n",
      "True difference: 0.00052\n",
      "k: 14.33\n",
      "6135 73458 0.08351711181899861\n",
      "Approx difference: 0.00022\n",
      "True difference: 0.00420\n",
      "k: 17.00\n",
      "7277 72316 0.10062780021018862\n",
      "Approx difference: 0.00012\n",
      "True difference: 0.00103\n",
      "k: 19.67\n",
      "8418 71175 0.1182718651211802\n",
      "Approx difference: 0.00015\n",
      "True difference: 0.00096\n",
      "k: 22.33\n",
      "9560 70033 0.1365070752359602\n",
      "Approx difference: 0.00017\n",
      "True difference: 0.00151\n",
      "k: 25.00\n",
      "10701 68892 0.15533008186727051\n",
      "Approx difference: -0.00009\n",
      "True difference: 0.00401\n",
      "\n",
      "Epsilon: 0.03\n",
      "k: 1.00\n",
      "428 79165 0.005406429609044401\n",
      "Approx difference: 0.00003\n",
      "True difference: 0.00100\n",
      "k: 3.67\n",
      "1569 78024 0.020109197170101508\n",
      "Approx difference: -0.00015\n",
      "True difference: 0.00061\n",
      "k: 6.33\n",
      "2711 76882 0.035261829817122343\n",
      "Approx difference: 0.00010\n",
      "True difference: 0.00168\n",
      "k: 9.00\n",
      "3852 75741 0.0508575276270448\n",
      "Approx difference: -0.00003\n",
      "True difference: 0.00104\n",
      "k: 11.67\n",
      "4994 74599 0.06694459711256183\n",
      "Approx difference: -0.00009\n",
      "True difference: 0.00474\n",
      "k: 14.33\n",
      "6135 73458 0.08351711181899861\n",
      "Approx difference: 0.00018\n",
      "True difference: 0.00059\n",
      "k: 17.00\n",
      "7277 72316 0.10062780021018862\n",
      "Approx difference: -0.00014\n",
      "True difference: 0.00089\n",
      "k: 19.67\n",
      "8418 71175 0.1182718651211802\n",
      "Approx difference: -0.00018\n",
      "True difference: 0.00247\n",
      "k: 22.33\n",
      "9560 70033 0.1365070752359602\n",
      "Approx difference: -0.00010\n",
      "True difference: 0.00332\n",
      "k: 25.00\n",
      "10701 68892 0.15533008186727051\n",
      "Approx difference: 0.00002\n",
      "True difference: 0.00380\n",
      "\n",
      "Epsilon: 0.04\n",
      "k: 1.00\n",
      "428 79165 0.005406429609044401\n",
      "Approx difference: -0.00007\n",
      "True difference: 0.00129\n",
      "k: 3.67\n",
      "1569 78024 0.020109197170101508\n",
      "Approx difference: 0.00003\n",
      "True difference: 0.00051\n",
      "k: 6.33\n",
      "2711 76882 0.035261829817122343\n",
      "Approx difference: 0.00002\n",
      "True difference: 0.00101\n",
      "k: 9.00\n",
      "3852 75741 0.0508575276270448\n",
      "Approx difference: 0.00004\n",
      "True difference: 0.00104\n",
      "k: 11.67\n",
      "4994 74599 0.06694459711256183\n",
      "Approx difference: -0.00015\n"
     ]
    }
   ],
   "source": [
    "all_orig_loss_e_k, all_est_loss_e_k, all_time = Main('diabetes', epsilons, k, rounds)\n",
    "# [round1[epsilon1[k1,...k10], epsilon2[k1,...k10],...], round2[...]]     \n",
    "\n",
    "with open('all_orig_loss_e_k_diabetes.txt', \"wb\") as file:   #Pickling\n",
    "    pickle.dump(all_orig_loss_e_k, file)\n",
    "\n",
    "with open('all_est_loss_e_k_diabetes.txt', \"wb\") as file2:   #Pickling\n",
    "    pickle.dump(all_est_loss_e_k, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1619a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_orig_loss_e_k_law.txt', 'rb') as f:\n",
    "    all_orig_loss_e_k = pickle.load(f)\n",
    "    \n",
    "with open('all_est_loss_e_k_law.txt', 'rb') as f:\n",
    "    all_est_loss_e_k = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ef165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [actual, estimate]\n",
    "\n",
    "sum_orig_loss_e_k = [[0 for _ in range(len(k))] for _ in range(len(epsilons))]\n",
    "sum_est_loss_e_k = [[0 for _ in range(len(k))] for _ in range(len(epsilons))]\n",
    "sum_time = [[0 for _ in range(len(k))] for _ in range(len(epsilons))]\n",
    "\n",
    "avg_orig_loss = []\n",
    "avg_est_loss = []\n",
    "avg_time = []\n",
    "\n",
    "for round_ in range(len(all_orig_loss_e_k)):\n",
    "    for e in range(len(epsilons)):\n",
    "        for k_ in range(len(k)):\n",
    "            sum_orig_loss_e_k[e][k_] = sum_orig_loss_e_k[e][k_] + all_orig_loss_e_k[round_][e][k_]\n",
    "            sum_est_loss_e_k[e][k_] = sum_est_loss_e_k[e][k_] + all_est_loss_e_k[round_][e][k_]\n",
    "            sum_time[e][k_] = sum_time[e][k_] + all_time[round_][e][k_]\n",
    "\n",
    "for e in range(len(epsilons)):\n",
    "    avg_orig_loss.append([ elem / len(all_orig_loss_e_k) for elem in sum_orig_loss_e_k[e]])\n",
    "    avg_est_loss.append([elem/ len(all_orig_loss_e_k) for elem in sum_est_loss_e_k[e]])\n",
    "    avg_time.append([elem/ len(all_orig_loss_e_k) for elem in sum_time[e]])\n",
    "\n",
    "k_e_orig = [[] for _ in range(len(k))]\n",
    "k_e_est = [[] for _ in range(len(k))]\n",
    "\n",
    "for e in range(len(epsilons)):\n",
    "    for k_ in range(len(k)):\n",
    "        k_e_orig[k_].append(avg_orig_loss[e][k_])\n",
    "        k_e_est[k_].append(avg_est_loss[e][k_])\n",
    "        \n",
    "print(k_e_est)\n",
    "\n",
    "averaged_time = []\n",
    "\n",
    "for e in range(len(epsilons)):\n",
    "    averaged_time.append(sum_time[e][0])\n",
    "\n",
    "average_time_final = sum(averaged_time) / len(averaged_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8527e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = np.linspace(1, 25, 10)\n",
    "k_ = list(k)\n",
    "k_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752355d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(k_e_orig)):\n",
    "    visualize_result(k_e_orig[i], k_e_est[i], epsilons, k_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d815add",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_g_ep = []\n",
    "spearman_g_k = []\n",
    "\n",
    "mae_g_ep = []\n",
    "mae_g_k = []\n",
    "    \n",
    "for i in range(len(avg_orig_loss)):\n",
    "    \n",
    "\n",
    "    spearman = []\n",
    "    mae = []\n",
    "    \n",
    "    for j in range(len(actual)):\n",
    "        spearman.append(spearmanr(actual[j], estimated[j]).correlation)\n",
    "        mae.append(mean_absolute_error(actual[j], estimated[j]))\n",
    "        \n",
    "    spearman_g_ep.append(spearman)\n",
    "    mae_g_ep.append(mae)\n",
    "    \n",
    "for i, kge in enumerate(k_g_e):\n",
    "    actual = [[x[0] for x in kge[0]], [x[0] for x in kge[1]]]#, [x[0] for x in kge[2]], [x[0] for x in kge[3]], [x[0] for x in kge[4]]]\n",
    "    estimated = [[x[1] for x in kge[0]], [x[1] for x in kge[1]]]#, [x[1] for x in kge[2]], [x[1] for x in kge[3]], [x[1] for x in kge[4]]]\n",
    "\n",
    "    spearman = []\n",
    "    mae = []\n",
    "    \n",
    "    for j in range(len(actual)):\n",
    "        spearman.append(spearmanr(actual[j], estimated[j]).correlation)\n",
    "        mae.append(mean_absolute_error(actual[j], estimated[j]))\n",
    "        \n",
    "    spearman_g_k.append(spearman)\n",
    "    mae_g_k.append(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_orig_loss[4])\n",
    "print(avg_est_loss[4])\n",
    "print()\n",
    "print(avg_orig_loss[13])\n",
    "print(avg_est_loss[13])\n",
    "print()\n",
    "print(avg_orig_loss[22])\n",
    "print(avg_est_loss[22])\n",
    "print()\n",
    "print(avg_orig_loss[ -5])\n",
    "print(avg_est_loss[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spearman_g_ep), len(spearman_g_ep[0])\n",
    "spearman_g_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spearman_g_k), len(spearman_g_k[0])\n",
    "spearman_g_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c888d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mae_g_ep), len(mae_g_ep[0])\n",
    "mae_g_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mae_g_k), len(mae_g_k[0])\n",
    "mae_g_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_est = [22, 20,23,21,19,18,16,17,15,14,12,13,11,10,9,8,7,6,4,5,3,2,1]\n",
    "rank_act = [23,20,21,22,17,18,16,19,14,15,13,12,11,10,8,7,9,6,4,5,2,3,1]\n",
    "a= np.cov(np.array(rank_est), np.array(rank_act), bias=True)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af31895",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.std(np.array(rank_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.std(np.array(rank_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a /(b*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f76788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb85715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
