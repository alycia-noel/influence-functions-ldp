{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0900bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import fairlearn.datasets as fd\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import grad\n",
    "from torch.autograd.functional import vhp\n",
    "from get_datasets import get_diabetes, get_adult, get_law\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "E = math.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558868a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_law():\n",
    "    data = pd.read_csv('data/lawschs1_1.csv')\n",
    "    \n",
    "    data = data[data.MissingRace != 1]\n",
    "    data = data.drop('Race', axis=1)\n",
    "    data = data.drop('MissingRace', axis=1)\n",
    "    data = data.drop('college', axis=1)\n",
    "    data = data.drop('Year', axis=1)\n",
    "    data = data.dropna(how='any', axis=0)\n",
    "\n",
    "    data['LSAT'] = data['LSAT'].apply(lambda x: round(x/10))\n",
    "    data['GPA'] = data['GPA'].apply(lambda x: round(x, 1))\n",
    "    \n",
    "    to_replace = ['LSAT', 'GPA']\n",
    "    data = pd.get_dummies(data, columns=to_replace, drop_first = False)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d236be",
   "metadata": {},
   "outputs": [],
   "source": [
    " class CreateData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        out_label = self.targets[idx]\n",
    "\n",
    "        return out_data, out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c371ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(num_features, 1, bias=False)\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.fc1(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def loss(self, logits, y):\n",
    "        loss = self.criterion(logits.ravel(), y)\n",
    "        \n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        thresh_results = []\n",
    "        \n",
    "        for p in probabilities:\n",
    "            if p>.5:\n",
    "                thresh_results.append(1)\n",
    "            else:\n",
    "                thresh_results.append(0)\n",
    "                \n",
    "        num_correct = 0\n",
    "        for r,y_ in zip(thresh_results, y):\n",
    "            if r == y_:\n",
    "                num_correct += 1\n",
    "                \n",
    "        acc = num_correct / len(y) * 100\n",
    "        prec = precision_score(y.detach().cpu().numpy(), thresh_results, zero_division=0) * 100\n",
    "        rec = recall_score(y.detach().cpu().numpy(), thresh_results) * 100\n",
    "        return loss, acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76ba609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, lr, bs, eps):\n",
    "    model.train()\n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "            \n",
    "    train_data = CreateData(dataset[0], dataset[1])\n",
    "    train_dataloader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "\n",
    "    for itr in range(0, eps):\n",
    "        itr_loss = 0\n",
    "        for i, [x,y] in enumerate(train_dataloader):\n",
    "            opt.zero_grad()\n",
    "            oupt = model(x)\n",
    "            \n",
    "            try:\n",
    "                loss_val = criterion(oupt.ravel(), y)\n",
    "            except ValueError:\n",
    "                loss_val = criterion(oupt, y)\n",
    "            itr_loss += loss_val\n",
    "            loss_val.backward()\n",
    "            opt.step() \n",
    "        #print(itr_loss/len(train_dataloader))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518df780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "data = get_law()\n",
    "label = 'admit'\n",
    "\n",
    "feature_set = set(data.columns) - {label}\n",
    "num_features = len(feature_set)\n",
    "\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74441026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main(lr, bs, eps):\n",
    "\n",
    "    device = 'cuda:5' if torch.cuda.is_available() else 'cpu'\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    \n",
    "    prec_avg = 0\n",
    "    rec_avg = 0\n",
    "    acc_avg = 0\n",
    "    loss_avg = 0\n",
    "    \n",
    "    data = get_law()\n",
    "    label = 'admit'\n",
    "\n",
    "    feature_set = set(data.columns) - {label}\n",
    "    num_features = len(feature_set)\n",
    "\n",
    "    X = data[feature_set]\n",
    "    y = data[label]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    new_train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "    train_sample_num = len(X_train)\n",
    "\n",
    "    x_test_input = torch.FloatTensor(X_test.values).to(device)\n",
    "    y_test_input = torch.FloatTensor(y_test.values).to(device)\n",
    "\n",
    "    x_train_input = torch.FloatTensor(X_train.values).to(device)\n",
    "    y_train_input = torch.FloatTensor(y_train.values).to(device)\n",
    "\n",
    "    ##############################################\n",
    "    # Train original model and get original loss #\n",
    "    ##############################################\n",
    "    torch_model = LogisticRegression(num_features)\n",
    "  \n",
    "    torch_model.to(device)\n",
    "    torch_model = train(torch_model, [x_train_input, y_train_input], lr, bs, eps)\n",
    "    test_loss, acc, prec, rec = torch_model.loss(torch_model(x_test_input), y_test_input)\n",
    "\n",
    "    prec_avg += prec\n",
    "    rec_avg += rec\n",
    "    acc_avg += acc\n",
    "    loss_avg += test_loss\n",
    "        \n",
    "    return prec_avg, rec_avg, acc_avg, loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de1b52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR: 0.01, BS: 1, Eps: 10\n",
      "Accuracy: 71.50\n",
      "Loss: 0.549\n",
      "Precision: 72.00\n",
      "Recall: 79.91\n",
      "\n",
      "LR: 0.01, BS: 8, Eps: 10\n",
      "Accuracy: 71.54\n",
      "Loss: 0.554\n",
      "Precision: 71.79\n",
      "Recall: 80.57\n",
      "\n",
      "LR: 0.01, BS: 16, Eps: 10\n",
      "Accuracy: 71.24\n",
      "Loss: 0.561\n",
      "Precision: 71.12\n",
      "Recall: 81.44\n",
      "\n",
      "LR: 0.01, BS: 32, Eps: 10\n",
      "Accuracy: 70.51\n",
      "Loss: 0.574\n",
      "Precision: 69.35\n",
      "Recall: 84.34\n",
      "\n",
      "LR: 0.01, BS: 1, Eps: 15\n"
     ]
    }
   ],
   "source": [
    "lr = [.01, .05, .1, .5]\n",
    "eps = [10, 15, 20, 25, 50]\n",
    "bs = [1, 8, 16, 32]\n",
    "\n",
    "for l in lr:\n",
    "    for e in eps:\n",
    "        for b in bs:\n",
    "            print(f'\\nLR: {l}, BS: {b}, Eps: {e}')\n",
    "            prec, rec, acc, loss = Main(l, b, e)\n",
    "            print(f'Accuracy: {acc:.2f}')\n",
    "            print(f'Loss: {loss:.3f}')\n",
    "            print(f'Precision: {prec:.2f}')\n",
    "            print(f'Recall: {rec:.2f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ea6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
