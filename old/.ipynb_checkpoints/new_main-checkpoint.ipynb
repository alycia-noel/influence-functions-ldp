{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e364451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import datetime\n",
    "import torch.optim as opt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn import linear_model\n",
    "from torch.autograd import grad, Variable\n",
    "from torch.autograd.functional import vhp\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from data_processing import get_data_adult\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = f\"cuda:5\"\n",
    "\n",
    "\n",
    "WEIGHT_DECAY = 1e-2\n",
    "TEST_INDEX = 5\n",
    "RECURSION_DEPTH = 26223\n",
    "SAMPLE_NUM = 100\n",
    "R = 1\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "train_dataloader, test_dataloader, num_features, train_dataset, all_data = get_data_adult(batch_size=256, randomize='false', epsilon=0.2)\n",
    "train_data_features, train_data_labels, test_data_features, test_data_labels = all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926f91d",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb475445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(data, acc_or_l, train_or_test, lr, batch_size):\n",
    "    sns.set(font_scale=1)\n",
    "\n",
    "    plt.plot(data, 'b-', linewidth=2.0)\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(acc_or_l)\n",
    "    plt.title(train_or_test + ' ' + acc_or_l + ' lr: ' + str(lr) + ' batch: ' + str(batch_size))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa662194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random():\n",
    "    random.seed(0)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(0)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07756821",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9daf5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisiticRegression(torch.nn.Module):\n",
    "    def __init__(self, weight_decay, input_size):\n",
    "        super(LogisiticRegression, self).__init__()\n",
    "        \n",
    "        self.wd = torch.FloatTensor([weight_decay]).to(device)\n",
    "        self.w = torch.nn.Parameter(torch.zeros([input_size], requires_grad=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = torch.matmul(x, torch.reshape(self.w, [-1,1]))\n",
    "        \n",
    "        return torch.sigmoid(logits)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c7499",
   "metadata": {},
   "source": [
    "### Influence Calculation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc60cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_influence_single(model, train_loader, test_loader, test_id_num, recursion_depth, r, loss_func):\n",
    "    \n",
    "    # calculate s_test vectors\n",
    "    x_test, y_test = test_loader.dataset[test_id_num]\n",
    "    x_test = test_loader.collate_fn([x_test])\n",
    "    y_test = test_loader.collate_fn([y_test])\n",
    "    s_test_vec = s_test_sample(model, x_test, y_test, train_loader, recursion_depth, r, loss_func)\n",
    "    \n",
    "    train_dataset_size = len(train_loader.dataset)\n",
    "    influences = []\n",
    "    \n",
    "    for i in tqdm(range(train_dataset_size)):\n",
    "        x, y = train_loader.dataset[i]\n",
    "        x = train_loader.collate_fn([x])\n",
    "        y = train_loader.collate_fn([y])\n",
    "        \n",
    "        grad_x_vec = grad_x(x, y, model, loss_func)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_influence = (\n",
    "                -sum([torch.sum(k * j).data\n",
    "                        for k, j in zip(grad_x_vec, s_test_vec)\n",
    "                    ]\n",
    "                )\n",
    "                / train_dataset_size\n",
    "            )\n",
    "            \n",
    "        influences.append(tmp_influence)\n",
    "    \n",
    "    harmful = np.argsort([inf.cpu() for inf in influences])\n",
    "    helpful = harmful[::-1]\n",
    "    \n",
    "    return influences, harmful.tolist(), helpful.tolist(), test_id_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e371a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_test_sample(model, x_test, y_test, train_loader, recursion_depth, r, loss_func):\n",
    "    inverse_hvp = [torch.zeros_like(params, dtype=torch.float) for params in model.parameters()]\n",
    "    \n",
    "    for i in range(r):\n",
    "        hessian_loader = DataLoader(train_loader.dataset, \n",
    "                                    sampler=torch.utils.data.RandomSampler(train_loader.dataset,\n",
    "                                                                           True,\n",
    "                                                                           num_samples = recursion_depth),\n",
    "                                   batch_size = 1,\n",
    "                                   num_workers = 4\n",
    "                                   )\n",
    "        cur_estimate, scale = s_test(x_test, y_test, model, i, hessian_loader, loss_func)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            inverse_hvp = [old + (cur / scale) for old, cur in zip(inverse_hvp, cur_estimate)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inverse_hvp = [component / r for component in inverse_hvp]\n",
    "\n",
    "    return inverse_hvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956886b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_test(x_test, y_test, model, i, sample_loader, loss_func):\n",
    "    damp = .0001\n",
    "    scale = 10\n",
    "    \n",
    "    v = grad_x(x_test, y_test, model, loss_func)\n",
    "    h_estimate = v\n",
    "    \n",
    "    params, names = make_functional(model)\n",
    "    \n",
    "    params = tuple(p.detach().requires_grad_() for p in params)\n",
    "    \n",
    "    progress_bar = tqdm(sample_loader, desc=f\"IHVP sample {i+1}\")\n",
    "    \n",
    "    for i, (x_train, y_train) in enumerate(progress_bar):\n",
    "        x_train, y_train = x_train.type(torch.FloatTensor).to(device), y_train.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        def f(*new_params):\n",
    "            load_weights(model, names, new_params)\n",
    "            out = model(x_train)\n",
    "            loss = calc_loss(out, y_train, loss_func)\n",
    "            return loss\n",
    "        \n",
    "        hv = vhp(f, params, tuple(h_estimate), strict=True)[1][0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            h_estimate = [\n",
    "                _v + (1 - damp) * _h_e - _hv / scale\n",
    "                for _v, _h_e, _hv in zip(v, h_estimate, hv)\n",
    "            ]\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                norm = sum([h_.norm() for h_ in h_estimate])\n",
    "                progress_bar.set_postfix({\"est_norm\": norm.item()})\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        load_weights(model, names, params, as_params=True)\n",
    "    \n",
    "    return h_estimate, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f2e41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_x(x_test, y_test, model, loss_func):\n",
    "    model.eval()\n",
    "    x_test, y_test = x_test.type(torch.FloatTensor).to(device), y_test.type(torch.FloatTensor).to(device)\n",
    "    prediction = model(x_test)\n",
    "    \n",
    "    loss = calc_loss(prediction, y_test, loss_func)\n",
    "    \n",
    "    return grad(loss, model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8e23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(prediction, y_test, loss_func):\n",
    "    if loss_func == \"cross_entropy\":\n",
    "        if prediction.shape[-1] == 1:\n",
    "            criterion = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = criterion(prediction, y_test.type(torch.float))\n",
    "        else:\n",
    "            criterion = torch.nn.cross_entropy()\n",
    "            loss = criterion(prediction, y_test)\n",
    "    elif loss_func == \"BCELoss\":\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        loss = criterion(prediction.ravel(), y_test)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1413935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_functional(model):\n",
    "    orig_params = tuple(model.parameters())\n",
    "    names = []\n",
    "    \n",
    "    for name, p in list(model.named_parameters()):\n",
    "        del_attr(model, name.split(\".\"))\n",
    "        names.append(name)\n",
    "    \n",
    "    return orig_params, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0232f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_attr(obj, names):\n",
    "    if len(names) == 1:\n",
    "        delattr(obj, names[0])\n",
    "    else:\n",
    "        del_attr(getattr(obj, names[0]), names[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98806be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_attr(obj, names, val):\n",
    "    if len(names) == 1:\n",
    "        setattr(obj, names[0], val)\n",
    "    else:\n",
    "        set_attr(getattr(obj, names[0]), names[1:], val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c996a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model, names, params, as_params=False):\n",
    "    for name, p in zip(names, params):\n",
    "        if not as_params:\n",
    "            set_attr(model, name.split(\".\"), p)\n",
    "        else:\n",
    "            set_attr(model, name.split(\".\"), torch.nn.Parameter(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f72f48",
   "metadata": {},
   "source": [
    "### Perform Influence Calculation and LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe081fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOO():\n",
    "    train_sample_num = len(train_data_features)\n",
    "    \n",
    "    class CreateData(torch.utils.data.Dataset):\n",
    "        def __init__(self, data, targets):\n",
    "            self.data = data\n",
    "            self.targets = targets\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            out_data = self.data[idx]\n",
    "            out_label = self.targets[idx]\n",
    "\n",
    "            return out_data, out_label\n",
    "    \n",
    "    train_data = CreateData(train_data_features, train_data_labels)\n",
    "    loo_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # prepare sklearn model to train w\n",
    "    C = 1.0 / (train_sample_num * WEIGHT_DECAY)\n",
    "    sklearn_model = linear_model.LogisticRegression(C=C, solver='newton-cg', tol=1e-8, fit_intercept=False)\n",
    "\n",
    "    torch_model = LogisiticRegression(WEIGHT_DECAY, num_features)\n",
    "\n",
    "    # train\n",
    "    sklearn_model.fit(train_data_features, train_data_labels.ravel())\n",
    "    print('lbfgs training took %s iter.' % sklearn_model.n_iter_)\n",
    "    \n",
    "    # assign W into pytorch model\n",
    "    w_opt = sklearn_model.coef_.ravel()\n",
    "    with torch.no_grad():\n",
    "        torch_model.w = torch.nn.Parameter(torch.tensor(w_opt, dtype=torch.float))\n",
    "        \n",
    "    # calculate original loss\n",
    "    x_test_input = torch.FloatTensor(test_data_features[TEST_INDEX:TEST_INDEX + 1])\n",
    "    y_test_input = torch.FloatTensor(test_data_labels[TEST_INDEX:TEST_INDEX + 1])\n",
    "    \n",
    "    test_data = CreateData(test_data_features[TEST_INDEX:TEST_INDEX + 1], test_data_labels[TEST_INDEX:TEST_INDEX + 1])\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "    \n",
    "    torch_model.to(device)\n",
    "    x_test_input, y_test_input = x_test_input.to(device), y_test_input.to(device)\n",
    "    \n",
    "    output = torch_model(x_test_input)\n",
    "    test_loss_ori = criterion(output.ravel(), y_test_input).detach().cpu().numpy()\n",
    "\n",
    "    loss_diff_approx, _, _, _ = calc_influence_single(torch_model, train_dataloader, test_dataloader, test_id_num=0, recursion_depth=RECURSION_DEPTH, r=R, loss_func=\"BCELoss\")\n",
    "    loss_diff_approx = -torch.FloatTensor(loss_diff_approx).cpu().numpy()\n",
    "    \n",
    "    # get high and low loss diff indicies\n",
    "    sorted_indicies = np.argsort(loss_diff_approx)\n",
    "    #sample_indicies = sorted_indicies[:int(SAMPLE_NUM)]\n",
    "    sample_indicies = np.concatenate([sorted_indicies[-int(SAMPLE_NUM/2):], sorted_indicies[:int(SAMPLE_NUM/2)]])\n",
    "  \n",
    "    # calculate true loss diff\n",
    "    loss_diff_true = np.zeros(SAMPLE_NUM)\n",
    "    for i, index in zip(range(SAMPLE_NUM), sample_indicies):\n",
    "        print('[{}/{}]'.format(i+1, SAMPLE_NUM))\n",
    "        \n",
    "        # get minus one dataset\n",
    "        x_train_minus_one = np.delete(train_data_features, index, axis=0)\n",
    "        y_train_minus_one = np.delete(train_data_labels, index, axis=0)\n",
    "        \n",
    "        # retrain\n",
    "        C = 1.0 / ((train_sample_num - 1)*WEIGHT_DECAY)\n",
    "        \n",
    "        sklearn_model_minus_one = linear_model.LogisticRegression(C=C, fit_intercept=False, tol=1e-8, solver='newton-cg')\n",
    "        sklearn_model_minus_one.fit(x_train_minus_one, y_train_minus_one.ravel())\n",
    "        print('LBFGS training took {} iter.'.format(sklearn_model_minus_one.n_iter_))\n",
    "        \n",
    "        # assign w on pytorch model\n",
    "        w_retrain = sklearn_model_minus_one.coef_.T.ravel()\n",
    "        with torch.no_grad():\n",
    "            torch_model.w = torch.nn.Parameter(torch.tensor(w_retrain, dtype=torch.float))\n",
    "            \n",
    "        torch_model.to(device)\n",
    "        \n",
    "        # get retrain loss\n",
    "        output_retrain = torch_model(x_test_input)\n",
    "        test_loss_retrain = criterion(output_retrain.ravel(), y_test_input).detach().cpu().numpy()\n",
    "        \n",
    "        loss_diff_true[i] = test_loss_retrain - test_loss_ori \n",
    "        \n",
    "        print('Original loss       :{}'.format(test_loss_ori))\n",
    "        print('Retrain loss        :{}'.format(test_loss_retrain))\n",
    "        print('True loss diff      :{}'.format(loss_diff_true[i]))\n",
    "        print('Estimated loss diff :{}'.format(loss_diff_approx[index]))\n",
    "    \n",
    "    return loss_diff_true, loss_diff_approx[sample_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0520deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs training took [16] iter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IHVP sample 1: 100%|███████████████████████████████████████████████| 26223/26223 [01:07<00:00, 387.60it/s, est_norm=684]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 26223/26223 [00:14<00:00, 1844.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1877537965774536\n",
      "True loss diff      :-3.2082200050354004e-05\n",
      "Estimated loss diff :0.000816871237475425\n",
      "[2/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1877383291721344\n",
      "True loss diff      :-4.754960536956787e-05\n",
      "Estimated loss diff :0.0008171835797838867\n",
      "[3/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1879560500383377\n",
      "True loss diff      :0.00017017126083374023\n",
      "Estimated loss diff :0.0008257308509200811\n",
      "[4/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18790195882320404\n",
      "True loss diff      :0.00011608004570007324\n",
      "Estimated loss diff :0.0008318149484694004\n",
      "[5/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18790195882320404\n",
      "True loss diff      :0.00011608004570007324\n",
      "Estimated loss diff :0.0008318149484694004\n",
      "[6/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18790195882320404\n",
      "True loss diff      :0.00011608004570007324\n",
      "Estimated loss diff :0.0008318149484694004\n",
      "[7/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18790195882320404\n",
      "True loss diff      :0.00011608004570007324\n",
      "Estimated loss diff :0.0008318149484694004\n",
      "[8/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18790195882320404\n",
      "True loss diff      :0.00011608004570007324\n",
      "Estimated loss diff :0.0008318149484694004\n",
      "[9/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18790195882320404\n",
      "True loss diff      :0.00011608004570007324\n",
      "Estimated loss diff :0.0008318149484694004\n",
      "[10/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18789389729499817\n",
      "True loss diff      :0.00010801851749420166\n",
      "Estimated loss diff :0.0008346485556103289\n",
      "[11/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772265315055847\n",
      "True loss diff      :-6.32256269454956e-05\n",
      "Estimated loss diff :0.0008359949570149183\n",
      "[12/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18777890503406525\n",
      "True loss diff      :-6.973743438720703e-06\n",
      "Estimated loss diff :0.0008395661716349423\n",
      "[13/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18783125281333923\n",
      "True loss diff      :4.537403583526611e-05\n",
      "Estimated loss diff :0.0008444060804322362\n",
      "[14/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878049373626709\n",
      "True loss diff      :1.9058585166931152e-05\n",
      "Estimated loss diff :0.0008453515474684536\n",
      "[15/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878718137741089\n",
      "True loss diff      :8.593499660491943e-05\n",
      "Estimated loss diff :0.0008455494535155594\n",
      "[16/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18779794871807098\n",
      "True loss diff      :1.2069940567016602e-05\n",
      "Estimated loss diff :0.000847746036015451\n",
      "[17/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18779794871807098\n",
      "True loss diff      :1.2069940567016602e-05\n",
      "Estimated loss diff :0.000847746036015451\n",
      "[18/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18775860965251923\n",
      "True loss diff      :-2.726912498474121e-05\n",
      "Estimated loss diff :0.000852100201882422\n",
      "[19/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18771187961101532\n",
      "True loss diff      :-7.399916648864746e-05\n",
      "Estimated loss diff :0.000855454767588526\n",
      "[20/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772956728935242\n",
      "True loss diff      :-5.631148815155029e-05\n",
      "Estimated loss diff :0.0008574775420129299\n",
      "[21/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18789921700954437\n",
      "True loss diff      :0.00011333823204040527\n",
      "Estimated loss diff :0.0008732552523724735\n",
      "[22/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18782255053520203\n",
      "True loss diff      :3.667175769805908e-05\n",
      "Estimated loss diff :0.0008741198107600212\n",
      "[23/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18773740530014038\n",
      "True loss diff      :-4.8473477363586426e-05\n",
      "Estimated loss diff :0.0008854180341586471\n",
      "[24/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18791569769382477\n",
      "True loss diff      :0.00012981891632080078\n",
      "Estimated loss diff :0.0008859222871251404\n",
      "[25/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18791569769382477\n",
      "True loss diff      :0.00012981891632080078\n",
      "Estimated loss diff :0.0008859222871251404\n",
      "[26/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18773962557315826\n",
      "True loss diff      :-4.6253204345703125e-05\n",
      "Estimated loss diff :0.0008898372179828584\n",
      "[27/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878625452518463\n",
      "True loss diff      :7.666647434234619e-05\n",
      "Estimated loss diff :0.0008947211899794638\n",
      "[28/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18786649405956268\n",
      "True loss diff      :8.061528205871582e-05\n",
      "Estimated loss diff :0.0008950263145379722\n",
      "[29/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18769338726997375\n",
      "True loss diff      :-9.24915075302124e-05\n",
      "Estimated loss diff :0.000896611250936985\n",
      "[30/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772467970848083\n",
      "True loss diff      :-6.119906902313232e-05\n",
      "Estimated loss diff :0.0009376336238346994\n",
      "[31/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18774330615997314\n",
      "True loss diff      :-4.2572617530822754e-05\n",
      "Estimated loss diff :0.0009557058219797909\n",
      "[32/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18776343762874603\n",
      "True loss diff      :-2.244114875793457e-05\n",
      "Estimated loss diff :0.0009672201704233885\n",
      "[33/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1879880577325821\n",
      "True loss diff      :0.000202178955078125\n",
      "Estimated loss diff :0.0009733357583172619\n",
      "[34/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18766404688358307\n",
      "True loss diff      :-0.00012183189392089844\n",
      "Estimated loss diff :0.0009845613967627287\n",
      "[35/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18766404688358307\n",
      "True loss diff      :-0.00012183189392089844\n",
      "Estimated loss diff :0.0009845613967627287\n",
      "[36/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1880316436290741\n",
      "True loss diff      :0.0002457648515701294\n",
      "Estimated loss diff :0.0010039586341008544\n",
      "[37/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18812048435211182\n",
      "True loss diff      :0.0003346055746078491\n",
      "Estimated loss diff :0.0010347506031394005\n",
      "[38/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772748112678528\n",
      "True loss diff      :-5.8397650718688965e-05\n",
      "Estimated loss diff :0.0010350613156333566\n",
      "[39/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18786397576332092\n",
      "True loss diff      :7.809698581695557e-05\n",
      "Estimated loss diff :0.0010544512188062072\n",
      "[40/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18781176209449768\n",
      "True loss diff      :2.588331699371338e-05\n",
      "Estimated loss diff :0.0010613348567858338\n",
      "[41/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772798776626587\n",
      "True loss diff      :-5.7891011238098145e-05\n",
      "Estimated loss diff :0.0010881779016926885\n",
      "[42/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876840442419052\n",
      "True loss diff      :-0.00010183453559875488\n",
      "Estimated loss diff :0.0011065845610573888\n",
      "[43/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18773826956748962\n",
      "True loss diff      :-4.760921001434326e-05\n",
      "Estimated loss diff :0.001127855503000319\n",
      "[44/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18792763352394104\n",
      "True loss diff      :0.00014175474643707275\n",
      "Estimated loss diff :0.0011668523075059056\n",
      "[45/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878223419189453\n",
      "True loss diff      :3.6463141441345215e-05\n",
      "Estimated loss diff :0.0011684780474752188\n",
      "[46/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1877909004688263\n",
      "True loss diff      :5.02169132232666e-06\n",
      "Estimated loss diff :0.0011744772782549262\n",
      "[47/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1877007931470871\n",
      "True loss diff      :-8.508563041687012e-05\n",
      "Estimated loss diff :0.0012417538091540337\n",
      "[48/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18787699937820435\n",
      "True loss diff      :9.112060070037842e-05\n",
      "Estimated loss diff :0.0012424796586856246\n",
      "[49/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876782923936844\n",
      "True loss diff      :-0.00010758638381958008\n",
      "Estimated loss diff :0.001293518696911633\n",
      "[50/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18780715763568878\n",
      "True loss diff      :2.1278858184814453e-05\n",
      "Estimated loss diff :0.001389295095577836\n",
      "[51/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18793338537216187\n",
      "True loss diff      :0.00014750659465789795\n",
      "Estimated loss diff :-0.0028779206331819296\n",
      "[52/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18767857551574707\n",
      "True loss diff      :-0.00010730326175689697\n",
      "Estimated loss diff :-0.00272469874471426\n",
      "[53/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18793684244155884\n",
      "True loss diff      :0.0001509636640548706\n",
      "Estimated loss diff :-0.002513706684112549\n",
      "[54/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18774962425231934\n",
      "True loss diff      :-3.625452518463135e-05\n",
      "Estimated loss diff :-0.0024527099449187517\n",
      "[55/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772035837173462\n",
      "True loss diff      :-6.552040576934814e-05\n",
      "Estimated loss diff :-0.002423189813271165\n",
      "[56/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18773236870765686\n",
      "True loss diff      :-5.3510069847106934e-05\n",
      "Estimated loss diff :-0.0024061233270913363\n",
      "[57/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18764974176883698\n",
      "True loss diff      :-0.0001361370086669922\n",
      "Estimated loss diff :-0.0022069858387112617\n",
      "[58/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18777473270893097\n",
      "True loss diff      :-1.1146068572998047e-05\n",
      "Estimated loss diff :-0.002184223849326372\n",
      "[59/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18777473270893097\n",
      "True loss diff      :-1.1146068572998047e-05\n",
      "Estimated loss diff :-0.002184223849326372\n",
      "[60/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18777422606945038\n",
      "True loss diff      :-1.1652708053588867e-05\n",
      "Estimated loss diff :-0.0021793628111481667\n",
      "[61/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876438409090042\n",
      "True loss diff      :-0.00014203786849975586\n",
      "Estimated loss diff :-0.0021726670674979687\n",
      "[62/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876227706670761\n",
      "True loss diff      :-0.00016310811042785645\n",
      "Estimated loss diff :-0.0021711746230721474\n",
      "[63/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18762724101543427\n",
      "True loss diff      :-0.00015863776206970215\n",
      "Estimated loss diff :-0.002149519044905901\n",
      "[64/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18762724101543427\n",
      "True loss diff      :-0.00015863776206970215\n",
      "Estimated loss diff :-0.002149519044905901\n",
      "[65/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18776501715183258\n",
      "True loss diff      :-2.086162567138672e-05\n",
      "Estimated loss diff :-0.002147807739675045\n",
      "[66/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18779507279396057\n",
      "True loss diff      :9.194016456604004e-06\n",
      "Estimated loss diff :-0.0021348961163312197\n",
      "[67/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878897249698639\n",
      "True loss diff      :0.00010384619235992432\n",
      "Estimated loss diff :-0.002122697187587619\n",
      "[68/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18761329352855682\n",
      "True loss diff      :-0.00017258524894714355\n",
      "Estimated loss diff :-0.0021136312279850245\n",
      "[69/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18787886202335358\n",
      "True loss diff      :9.298324584960938e-05\n",
      "Estimated loss diff :-0.0021100968588143587\n",
      "[70/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18773797154426575\n",
      "True loss diff      :-4.7907233238220215e-05\n",
      "Estimated loss diff :-0.002098526805639267\n",
      "[71/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18813063204288483\n",
      "True loss diff      :0.0003447532653808594\n",
      "Estimated loss diff :-0.002097468823194504\n",
      "[72/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18779371678829193\n",
      "True loss diff      :7.838010787963867e-06\n",
      "Estimated loss diff :-0.002082233550027013\n",
      "[73/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18774135410785675\n",
      "True loss diff      :-4.45246696472168e-05\n",
      "Estimated loss diff :-0.002065628534182906\n",
      "[74/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878894418478012\n",
      "True loss diff      :0.00010356307029724121\n",
      "Estimated loss diff :-0.0020368772093206644\n",
      "[75/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18777422606945038\n",
      "True loss diff      :-1.1652708053588867e-05\n",
      "Estimated loss diff :-0.0019863613415509462\n",
      "[76/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18777422606945038\n",
      "True loss diff      :-1.1652708053588867e-05\n",
      "Estimated loss diff :-0.0019863613415509462\n",
      "[77/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18777422606945038\n",
      "True loss diff      :-1.1652708053588867e-05\n",
      "Estimated loss diff :-0.0019863613415509462\n",
      "[78/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18765737116336823\n",
      "True loss diff      :-0.0001285076141357422\n",
      "Estimated loss diff :-0.001976235769689083\n",
      "[79/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18768037855625153\n",
      "True loss diff      :-0.0001055002212524414\n",
      "Estimated loss diff :-0.0019393123220652342\n",
      "[80/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18801172077655792\n",
      "True loss diff      :0.00022584199905395508\n",
      "Estimated loss diff :-0.0019327409099787474\n",
      "[81/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18767885863780975\n",
      "True loss diff      :-0.00010702013969421387\n",
      "Estimated loss diff :-0.0019099400378763676\n",
      "[82/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18767885863780975\n",
      "True loss diff      :-0.00010702013969421387\n",
      "Estimated loss diff :-0.0019099400378763676\n",
      "[83/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876714527606964\n",
      "True loss diff      :-0.00011442601680755615\n",
      "Estimated loss diff :-0.0018883864395320415\n",
      "[84/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18762198090553284\n",
      "True loss diff      :-0.00016389787197113037\n",
      "Estimated loss diff :-0.0018740842351689935\n",
      "[85/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876840442419052\n",
      "True loss diff      :-0.00010183453559875488\n",
      "Estimated loss diff :-0.0018601263873279095\n",
      "[86/100]\n",
      "LBFGS training took [15] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878625452518463\n",
      "True loss diff      :7.666647434234619e-05\n",
      "Estimated loss diff :-0.0018491917289793491\n",
      "[87/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876508891582489\n",
      "True loss diff      :-0.00013498961925506592\n",
      "Estimated loss diff :-0.0018462204607203603\n",
      "[88/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1876247227191925\n",
      "True loss diff      :-0.0001611560583114624\n",
      "Estimated loss diff :-0.001837100018747151\n",
      "[89/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18774855136871338\n",
      "True loss diff      :-3.732740879058838e-05\n",
      "Estimated loss diff :-0.001822841353714466\n",
      "[90/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.187800332903862\n",
      "True loss diff      :1.4454126358032227e-05\n",
      "Estimated loss diff :-0.0018193438882008195\n",
      "[91/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18782155215740204\n",
      "True loss diff      :3.567337989807129e-05\n",
      "Estimated loss diff :-0.0018155110301449895\n",
      "[92/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18782155215740204\n",
      "True loss diff      :3.567337989807129e-05\n",
      "Estimated loss diff :-0.0018155110301449895\n",
      "[93/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18782155215740204\n",
      "True loss diff      :3.567337989807129e-05\n",
      "Estimated loss diff :-0.0018155110301449895\n",
      "[94/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18782155215740204\n",
      "True loss diff      :3.567337989807129e-05\n",
      "Estimated loss diff :-0.0018155110301449895\n",
      "[95/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18798236548900604\n",
      "True loss diff      :0.0001964867115020752\n",
      "Estimated loss diff :-0.0018119047163054347\n",
      "[96/100]\n",
      "LBFGS training took [17] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18781593441963196\n",
      "True loss diff      :3.0055642127990723e-05\n",
      "Estimated loss diff :-0.0017924788407981396\n",
      "[97/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878090351819992\n",
      "True loss diff      :2.3156404495239258e-05\n",
      "Estimated loss diff :-0.001792392460629344\n",
      "[98/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.1878090351819992\n",
      "True loss diff      :2.3156404495239258e-05\n",
      "Estimated loss diff :-0.001792392460629344\n",
      "[99/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772295117378235\n",
      "True loss diff      :-6.292760372161865e-05\n",
      "Estimated loss diff :-0.0017883063992485404\n",
      "[100/100]\n",
      "LBFGS training took [16] iter.\n",
      "Original loss       :0.18778587877750397\n",
      "Retrain loss        :0.18772295117378235\n",
      "True loss diff      :-6.292760372161865e-05\n",
      "Estimated loss diff :-0.0017883063992485404\n"
     ]
    }
   ],
   "source": [
    "loss_diff_true, loss_diff_approx = LOO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd5b9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(actual_loss_diff, estimated_loss_diff):\n",
    "    r2_s = r2_score(actual_loss_diff, estimated_loss_diff)\n",
    "\n",
    "    max_abs = np.max([np.abs(actual_loss_diff), np.abs(estimated_loss_diff)])\n",
    "    min_, max_ = -max_abs * 1.1, max_abs * 1.1\n",
    "    plt.rcParams['figure.figsize'] = 6, 5\n",
    "    plt.scatter(actual_loss_diff, estimated_loss_diff, zorder=2, s=10)\n",
    "    plt.title('Loss diff')\n",
    "    plt.xlabel('Actual loss diff')\n",
    "    plt.ylabel('Estimated loss diff')\n",
    "    range_ = [min_, max_]\n",
    "    plt.plot(range_, range_, 'k-', alpha=0.2, zorder=1)\n",
    "    text = 'MAE = {:.03}\\nR2 score = {:.03}'.format(mean_absolute_error(actual_loss_diff, estimated_loss_diff),\n",
    "                                                    r2_s)\n",
    "    plt.text(max_abs, -max_abs, text, verticalalignment='bottom', horizontalalignment='right')\n",
    "    plt.xlim(min_, max_)\n",
    "    plt.ylim(min_, max_)\n",
    "\n",
    "    plt.savefig(\"result.png\")\n",
    "\n",
    "    return r2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b32c21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_score_ = visualize_result(loss_diff_true, loss_diff_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a61b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
